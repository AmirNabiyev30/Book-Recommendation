{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6abfd161",
   "metadata": {},
   "source": [
    "This notebook serves as an example on how collaborative filtering works\n",
    "\n",
    "We have a sparse matrix and we want to be able to predict values for \"ratings\" of items that the user hasnt seen yet. Learning the entire matrix is an approach but becomse unfeasible with size\n",
    "\n",
    "A better more traditional approach is using a matrix factorization and learning these smaller matrices. They reduce the amount of parameters and grow less with size compared to the orginal sparse matrix. We randomly intitliaze these smaller matrices and use graident desecent on data we do know to tune these matrices.\n",
    "\n",
    "We are going to use L2 regularization to reduce variance and stop parameters from shooting up but I will show a comparsion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7c7ee654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 None 3 4 3]\n",
      " [2 1 2 1 None]\n",
      " [1 None 3 4 3]]\n",
      "(3, 5)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#lets create an example sparse matrix that looks like this\n",
    "\n",
    "ratings  = np.array(\n",
    "    [[1, None, 3 ,  4 , 3],\n",
    "    [2,1,2,1,None],\n",
    "    [1,None,3,4,3]]\n",
    ")\n",
    "\n",
    "print(ratings)\n",
    "print(ratings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16277c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1]\n",
      " [0 2 3]\n",
      " [0 3 4]\n",
      " [0 4 3]\n",
      " [1 0 2]\n",
      " [1 1 1]\n",
      " [1 2 2]\n",
      " [1 3 1]\n",
      " [2 0 1]\n",
      " [2 2 3]\n",
      " [2 3 4]\n",
      " [2 4 3]]\n"
     ]
    }
   ],
   "source": [
    "#now that we have our ratings matrix, we can craete our smaller matrices for users and items \n",
    "#we need the dimensions to match\n",
    "# m x n  * n x p = m x p\n",
    "#so if ratings is a 3 x 5, the first matrix should be a 3 x k and the second matrix should be a k x 5\n",
    "\n",
    "\n",
    "#we can choose k = 2 for this example\n",
    "k = 2\n",
    "\n",
    "\n",
    "\n",
    "#we can compute predicted ratings but first we need to train the matrices U and V and adjust them based on known ratings\n",
    "\n",
    "#we can use gradient descent for this but first we need to fitler for known ratings\n",
    "\n",
    "#we can iterate through the ratings matrix \n",
    "data = []\n",
    "for i in range(ratings.shape[0]):\n",
    "    for j in range(ratings.shape[1]):\n",
    "        if ratings[i][j] is not None:\n",
    "            data.append((i,j,ratings[i][j])) # (user_index, item_index, rating)\n",
    "data = np.array(data)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "217372c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data: [[1 1 1]\n",
      " [0 3 4]\n",
      " [0 2 3]\n",
      " [2 4 3]\n",
      " [1 0 2]\n",
      " [1 3 1]\n",
      " [0 4 3]\n",
      " [1 2 2]]\n",
      "Test Data: [[2 3 4]\n",
      " [2 2 3]\n",
      " [0 0 1]\n",
      " [2 0 1]]\n"
     ]
    }
   ],
   "source": [
    "#now we import scikit and pytorch to do train-test spilt and gradient descent with an optimizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train,test = train_test_split(data,test_size=.3,random_state = 42)\n",
    "print(\"Train Data:\", train)\n",
    "print(\"Test Data:\", test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0068155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/200, Loss: 4.8457\n",
      "Epoch 40/200, Loss: 3.3065\n",
      "Epoch 60/200, Loss: 2.6665\n",
      "Epoch 80/200, Loss: 2.1397\n",
      "Epoch 100/200, Loss: 1.5922\n",
      "Epoch 120/200, Loss: 0.9444\n",
      "Epoch 140/200, Loss: 0.3497\n",
      "Epoch 160/200, Loss: 0.0669\n",
      "Epoch 180/200, Loss: 0.0086\n",
      "Epoch 200/200, Loss: 0.0009\n",
      "Test Loss: 1.7717\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "#we are creating a custom model for pytorch\n",
    "class FactorizationModel(nn.Module):\n",
    "    def __init__(self,num_users,num_items,num_factors):\n",
    "        super(FactorizationModel,self).__init__()\n",
    "        #creates our smaller matrices, intialized randomly and doesnt follow traditioanal tensor initialization\n",
    "        self.U = nn.Embedding(num_users,num_factors) # 3x2\n",
    "        self.V = nn.Embedding(num_items,num_factors) # 2x5\n",
    "\n",
    "\n",
    "    def forward(self,user_indices,item_indices):\n",
    "        #this is how our predictions are computed\n",
    "        user_factors = self.U(user_indices)\n",
    "        item_factors = self.V(item_indices)\n",
    "        #dot product\n",
    "        return (user_factors * item_factors).sum(1)\n",
    "    \n",
    "\n",
    "model = FactorizationModel(num_users=3,num_items=5,num_factors=k)\n",
    "#define optimizer and loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.02,weight_decay=1e-5)\n",
    "loss_fn = nn.MSELoss() \n",
    "#training loop\n",
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    #set the model to training mode\n",
    "    model.train()\n",
    "    #zero out the gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    user_indices = torch.LongTensor(train[:,0])\n",
    "    item_indices = torch.LongTensor(train[:,1])\n",
    "    ratings = torch.FloatTensor(train[:,2])\n",
    "\n",
    "    predictions = model(user_indices,item_indices)\n",
    "    loss = loss_fn(predictions,ratings)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 20 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}\")\n",
    "    \n",
    "#evaluate on test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    user_indices = torch.LongTensor(test[:,0])\n",
    "    item_indices = torch.LongTensor(test[:,1])\n",
    "    ratings = torch.FloatTensor(test[:,2])\n",
    "\n",
    "    predictions = model(user_indices,item_indices)\n",
    "    loss = loss_fn(predictions,ratings)\n",
    "    print(f\"Test Loss: {loss.item():.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f279efba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Ratings Matrix:\n",
      "tensor([[-0.0840, -2.6346,  2.9952,  3.9801,  3.0081],\n",
      "        [ 2.0092,  1.0067,  1.9492,  1.0552,  2.3200],\n",
      "        [ 2.1054,  0.5644,  2.6246,  1.8672,  3.0185]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "guess_matrix = torch.matmul(model.U.weight,model.V.weight.t())\n",
    "print(\"Predicted Ratings Matrix:\")\n",
    "print(guess_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5b74b984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Ratings Matrix:\n",
      "[[1 None 3 4 3]\n",
      " [2 1 2 1 None]\n",
      " [1 None 3 4 3]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Ratings Matrix:\")\n",
    "print(ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71eca28",
   "metadata": {},
   "source": [
    "With more training data and adjustments to epoch and learning rate, we can improve our guesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c117ffc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id        isbn  rating\n",
      "0   276725  034545104X       0\n",
      "1   276726  0155061224       5\n",
      "2   276727  0446520802       0\n",
      "3   276729  052165615X       3\n",
      "4   276729  0521795028       6\n"
     ]
    }
   ],
   "source": [
    "#querying the database\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "conn = sqlite3.connect('./backend/main.db')\n",
    "\n",
    "query = \"SELECT user_id,isbn,rating FROM ratings\"\n",
    "\n",
    "\n",
    "df = pd.read_sql_query(query,conn)\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57142d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id        isbn  rating\n",
      "0   276725  034545104X       0\n",
      "1   276726  0155061224       5\n",
      "2   276727  0446520802       0\n",
      "3   276729  052165615X       3\n",
      "4   276729  0521795028       6\n"
     ]
    }
   ],
   "source": [
    "df[\"isbn\"] = (\n",
    "    df[\"isbn\"]\n",
    "    .astype(str)\n",
    "    .str.replace(\"-\", \"\")\n",
    "    .str.strip()\n",
    ")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa124703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "340553"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"isbn\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef1deb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
